{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine Learning 01.112: HW1",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "7NujvcDv6fr5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**1 (a) Let $\\theta \\in \\mathbb{R}^d$ be a vector and $\\theta_0 \\in \\mathbb{R}$ be a constant. Let $x = [x_1, ..., x_d]$ be a vector of unknowns. Consider the hyperplane in $\\mathbb{R}^d$ whose equation is given by $\\theta\\cdot x + \\theta_0 = 0$. Given a point $y \\in \\mathbb{R}^d$, find its distance to the hyperplane.** "
      ]
    },
    {
      "metadata": {
        "id": "DyTxp57V7ZT-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![alt text](https://github.com/charleswongzx/machine-learning-01.112/blob/master/HW1-1.jpg?raw=true)"
      ]
    },
    {
      "metadata": {
        "id": "GXU2aa306uHO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**1 (b) Let $X$ and $Y$ be independent Poisson random variables, i.e. **\n",
        "\\begin{equation}\n",
        "  \\mathbb{P}(X = x) = \\frac{\\alpha^x e^{-\\alpha}}{x!}, \\:\\:\\: \\mathbb{P}(Y = y) = \\frac{\\beta^y e^{-\\beta}}{y!}, \\:\\:\\: \\text{for all } x,y \\geq 0\n",
        "\\end{equation}\n",
        "**for some rates $\\alpha, \\beta > 0$. Show that $Z = X + Y$ is also Poisson, and find its rate $\\gamma$. **"
      ]
    },
    {
      "metadata": {
        "id": "awkEEW2CF2kK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![alt text](https://github.com/charleswongzx/machine-learning-01.112/blob/master/HW1-2.jpg?raw=true)"
      ]
    },
    {
      "metadata": {
        "id": "GLM38BRD6WDb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***2 (a) Write down the version of Python and the version of Theano you are using.***"
      ]
    },
    {
      "metadata": {
        "id": "rnsU2qcN6TK-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "1ca0a761-a5db-4f9d-9234-c357bb956c87"
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import theano\n",
        "print ('Python version:', sys.version)\n",
        "print('Theano version:', theano.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python version: 3.6.3 (default, Oct  3 2017, 21:45:48) \n",
            "[GCC 7.2.0]\n",
            "Theano version: 1.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PL047G53X90j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***3 (a) Write down the vector w of coefficients computed by gradient descent.***"
      ]
    },
    {
      "metadata": {
        "id": "LwMlkcP0OzQ4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "csv = 'https://www.dropbox.com/s/oqoyy9p849ewzt2/linear.csv?dl=1'\n",
        "data = np.genfromtxt(csv,delimiter=',')\n",
        "X = data[:,1:]\n",
        "Y = data[:,0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u8M5yRW_O0A5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import theano.tensor as T\n",
        "d = X.shape[1] # dimension of feature vectors\n",
        "n = X.shape[0] # number of training samples\n",
        "learn_rate = 0.5 # learning rate for gradient descent"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ge0yYm3fPMXm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = T.matrix(name='x') # feature matrix\n",
        "y = T.vector(name='y') # response vector\n",
        "w = theano.shared(np.zeros((d,1)),name='w') # model parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sKz5M0-aPQc4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "risk = T.sum((T.dot(x,w).T - y)**2)/2/n # empirical risk\n",
        "grad_risk = T.grad(risk, wrt=w) # gradient of the risk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0Pv99vowPZ-_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_model = theano.function(inputs=[],\n",
        "outputs=risk,\n",
        "updates=[(w, w-learn_rate*grad_risk)],\n",
        "givens={x:X, y:Y})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CH6UDjW4PdGY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4409
        },
        "outputId": "efb5622c-48a7-4a2b-b790-c23ad7439e21"
      },
      "cell_type": "code",
      "source": [
        "n_steps = 50\n",
        "gd_start = time.time()\n",
        "\n",
        "for i in range(n_steps):\n",
        "  print('Risk:',train_model())\n",
        "  print('w=',w.get_value())\n",
        "  \n",
        "gd_end = time.time()\n",
        "print(\"Gradient descent time elapsed:\", gd_end-gd_start, \"seconds\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Risk: 2.619322008585456\n",
            "w= [[-0.40989365]\n",
            " [ 0.58200428]\n",
            " [-0.03422747]\n",
            " [-0.84429332]]\n",
            "Risk: 0.7587559422725657\n",
            "w= [[-0.56425042]\n",
            " [ 0.91043645]\n",
            " [-0.03598075]\n",
            " [-1.30070194]]\n",
            "Risk: 0.2354281222497302\n",
            "w= [[-0.61197745]\n",
            " [ 1.09756651]\n",
            " [-0.02729178]\n",
            " [-1.55159757]]\n",
            "Risk: 0.07939576047330815\n",
            "w= [[-0.61854675]\n",
            " [ 1.2052004 ]\n",
            " [-0.0168923 ]\n",
            " [-1.69176458]]\n",
            "Risk: 0.0300968963645766\n",
            "w= [[-0.61159653]\n",
            " [ 1.26766213]\n",
            " [-0.00782182]\n",
            " [-1.77127007]]\n",
            "Risk: 0.013695201975103273\n",
            "w= [[-6.02022776e-01]\n",
            " [ 1.30420333e+00]\n",
            " [-7.98156865e-04]\n",
            " [-1.81700086e+00]]\n",
            "Risk: 0.0080060923088713\n",
            "w= [[-0.59358047]\n",
            " [ 1.32573352]\n",
            " [ 0.00431825]\n",
            " [-1.84363622]]\n",
            "Risk: 0.005970446508700007\n",
            "w= [[-0.58715742]\n",
            " [ 1.33849761]\n",
            " [ 0.00791253]\n",
            " [-1.85932124]]\n",
            "Risk: 0.005225932117259178\n",
            "w= [[-0.58261402]\n",
            " [ 1.34610447]\n",
            " [ 0.01037892]\n",
            " [-1.86864581]]\n",
            "Risk: 0.004949550127903777\n",
            "w= [[-0.57953393]\n",
            " [ 1.35065778]\n",
            " [ 0.01204429]\n",
            " [-1.8742339 ]]\n",
            "Risk: 0.004845924776165539\n",
            "w= [[-0.57750185]\n",
            " [ 1.35339322]\n",
            " [ 0.0131559 ]\n",
            " [-1.87760536]]\n",
            "Risk: 0.004806813029966769\n",
            "w= [[-0.57618562]\n",
            " [ 1.35504147]\n",
            " [ 0.01389158]\n",
            " [-1.87965081]]\n",
            "Risk: 0.004791984242871618\n",
            "w= [[-0.57534402]\n",
            " [ 1.35603705]\n",
            " [ 0.01437531]\n",
            " [-1.88089746]]\n",
            "Risk: 0.004786344307210617\n",
            "w= [[-0.57481089]\n",
            " [ 1.35663958]\n",
            " [ 0.01469176]\n",
            " [-1.88166009]]\n",
            "Risk: 0.0047841942688007875\n",
            "w= [[-0.57447547]\n",
            " [ 1.35700482]\n",
            " [ 0.01489794]\n",
            " [-1.88212804]]\n",
            "Risk: 0.004783373170821499\n",
            "w= [[-0.57426551]\n",
            " [ 1.3572265 ]\n",
            " [ 0.01503184]\n",
            " [-1.88241589]]\n",
            "Risk: 0.004783059133878647\n",
            "w= [[-0.57413457]\n",
            " [ 1.35736119]\n",
            " [ 0.01511856]\n",
            " [-1.88259329]]\n",
            "Risk: 0.0047829388748837675\n",
            "w= [[-0.57405316]\n",
            " [ 1.3574431 ]\n",
            " [ 0.0151746 ]\n",
            " [-1.88270281]]\n",
            "Risk: 0.004782892769416027\n",
            "w= [[-0.57400264]\n",
            " [ 1.35749293]\n",
            " [ 0.01521074]\n",
            " [-1.88277051]]\n",
            "Risk: 0.004782875074349401\n",
            "w= [[-0.57397135]\n",
            " [ 1.35752327]\n",
            " [ 0.01523401]\n",
            " [-1.88281241]]\n",
            "Risk: 0.004782868276122441\n",
            "w= [[-0.57395198]\n",
            " [ 1.35754175]\n",
            " [ 0.01524896]\n",
            " [-1.88283836]]\n",
            "Risk: 0.004782865661743263\n",
            "w= [[-0.57394001]\n",
            " [ 1.35755301]\n",
            " [ 0.01525857]\n",
            " [-1.88285444]]\n",
            "Risk: 0.004782864655366253\n",
            "w= [[-0.57393262]\n",
            " [ 1.35755987]\n",
            " [ 0.01526473]\n",
            " [-1.88286442]]\n",
            "Risk: 0.0047828642676054\n",
            "w= [[-0.57392805]\n",
            " [ 1.35756405]\n",
            " [ 0.01526867]\n",
            " [-1.88287061]]\n",
            "Risk: 0.00478286411806061\n",
            "w= [[-0.57392523]\n",
            " [ 1.3575666 ]\n",
            " [ 0.01527119]\n",
            " [-1.88287445]]\n",
            "Risk: 0.004782864060333996\n",
            "w= [[-0.57392349]\n",
            " [ 1.35756816]\n",
            " [ 0.01527281]\n",
            " [-1.88287684]]\n",
            "Risk: 0.004782864038030564\n",
            "w= [[-0.57392241]\n",
            " [ 1.35756911]\n",
            " [ 0.01527384]\n",
            " [-1.88287832]]\n",
            "Risk: 0.004782864029405725\n",
            "w= [[-0.57392175]\n",
            " [ 1.35756969]\n",
            " [ 0.0152745 ]\n",
            " [-1.88287925]]\n",
            "Risk: 0.004782864026067557\n",
            "w= [[-0.57392134]\n",
            " [ 1.35757004]\n",
            " [ 0.01527492]\n",
            " [-1.88287982]]\n",
            "Risk: 0.004782864024774455\n",
            "w= [[-0.57392109]\n",
            " [ 1.35757025]\n",
            " [ 0.01527519]\n",
            " [-1.88288018]]\n",
            "Risk: 0.004782864024273131\n",
            "w= [[-0.57392093]\n",
            " [ 1.35757039]\n",
            " [ 0.01527536]\n",
            " [-1.8828804 ]]\n",
            "Risk: 0.004782864024078618\n",
            "w= [[-0.57392084]\n",
            " [ 1.35757047]\n",
            " [ 0.01527546]\n",
            " [-1.88288054]]\n",
            "Risk: 0.004782864024003078\n",
            "w= [[-0.57392078]\n",
            " [ 1.35757051]\n",
            " [ 0.01527553]\n",
            " [-1.88288062]]\n",
            "Risk: 0.004782864023973728\n",
            "w= [[-0.57392074]\n",
            " [ 1.35757054]\n",
            " [ 0.01527558]\n",
            " [-1.88288068]]\n",
            "Risk: 0.004782864023962314\n",
            "w= [[-0.57392072]\n",
            " [ 1.35757056]\n",
            " [ 0.01527561]\n",
            " [-1.88288071]]\n",
            "Risk: 0.004782864023957864\n",
            "w= [[-0.57392071]\n",
            " [ 1.35757057]\n",
            " [ 0.01527562]\n",
            " [-1.88288073]]\n",
            "Risk: 0.004782864023956135\n",
            "w= [[-0.5739207 ]\n",
            " [ 1.35757058]\n",
            " [ 0.01527563]\n",
            " [-1.88288074]]\n",
            "Risk: 0.004782864023955461\n",
            "w= [[-0.57392069]\n",
            " [ 1.35757058]\n",
            " [ 0.01527564]\n",
            " [-1.88288075]]\n",
            "Risk: 0.004782864023955196\n",
            "w= [[-0.57392069]\n",
            " [ 1.35757059]\n",
            " [ 0.01527565]\n",
            " [-1.88288076]]\n",
            "Risk: 0.004782864023955096\n",
            "w= [[-0.57392069]\n",
            " [ 1.35757059]\n",
            " [ 0.01527565]\n",
            " [-1.88288076]]\n",
            "Risk: 0.004782864023955056\n",
            "w= [[-0.57392068]\n",
            " [ 1.35757059]\n",
            " [ 0.01527565]\n",
            " [-1.88288076]]\n",
            "Risk: 0.004782864023955042\n",
            "w= [[-0.57392068]\n",
            " [ 1.35757059]\n",
            " [ 0.01527565]\n",
            " [-1.88288076]]\n",
            "Risk: 0.0047828640239550345\n",
            "w= [[-0.57392068]\n",
            " [ 1.35757059]\n",
            " [ 0.01527565]\n",
            " [-1.88288076]]\n",
            "Risk: 0.00478286402395503\n",
            "w= [[-0.57392068]\n",
            " [ 1.35757059]\n",
            " [ 0.01527565]\n",
            " [-1.88288076]]\n",
            "Risk: 0.004782864023955031\n",
            "w= [[-0.57392068]\n",
            " [ 1.35757059]\n",
            " [ 0.01527565]\n",
            " [-1.88288076]]\n",
            "Risk: 0.004782864023955029\n",
            "w= [[-0.57392068]\n",
            " [ 1.35757059]\n",
            " [ 0.01527565]\n",
            " [-1.88288076]]\n",
            "Risk: 0.004782864023955027\n",
            "w= [[-0.57392068]\n",
            " [ 1.35757059]\n",
            " [ 0.01527565]\n",
            " [-1.88288076]]\n",
            "Risk: 0.0047828640239550285\n",
            "w= [[-0.57392068]\n",
            " [ 1.35757059]\n",
            " [ 0.01527565]\n",
            " [-1.88288076]]\n",
            "Risk: 0.004782864023955029\n",
            "w= [[-0.57392068]\n",
            " [ 1.35757059]\n",
            " [ 0.01527565]\n",
            " [-1.88288076]]\n",
            "Risk: 0.004782864023955034\n",
            "w= [[-0.57392068]\n",
            " [ 1.35757059]\n",
            " [ 0.01527565]\n",
            " [-1.88288076]]\n",
            "Gradient descent time elapsed: 0.09109354019165039 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lfNZQDqDXwBo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***b) Write a program which calculates the exact solution for the optimal coefficients in the linear regression problem. Compare your solution with the answer in (a).***"
      ]
    },
    {
      "metadata": {
        "id": "espxdUfPPjFp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a5b19057-9e2a-4400-b490-4dd4cdd475c3"
      },
      "cell_type": "code",
      "source": [
        "from numpy.linalg import inv\n",
        "\n",
        "la_start = time.time()\n",
        "b = inv(X.T.dot(X)).dot(X.T).dot(Y)  # matrix linear regression inverse\n",
        "la_end = time.time()\n",
        "\n",
        "print('Linear inv time elapsed:', la_end-la_start, 'seconds')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear inv time elapsed: 0.005253791809082031 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qwLme8uUUFqi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "87102e6c-9e54-4ef8-d25b-42d0337670c1"
      },
      "cell_type": "code",
      "source": [
        "print(b.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pLlqCU-VYax7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The result calculated using simple linear algebra matches the result from gradient descent. It is noted that the method in (b) was an order of magnitude faster at 0.0130s compared to (a) at 0.535s. This is, however, influenced by n_steps declared for (a). (a) appears to converge on the solution before step 50, and can be optimised further.\n",
        "\n",
        "A possible optimisation is to end subsequent descent steps after matching parameters between step n and n-1 have been achieved."
      ]
    },
    {
      "metadata": {
        "id": "tTW6IifQaHrj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***(c) Find a Python library that computes the optimal coefficients in the linear regression\n",
        "problem, and compare its solution with the answer in (a).***"
      ]
    },
    {
      "metadata": {
        "id": "zNeVEzdXXlD4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "105bef21-c3ae-4c7d-d0c0-5a688ace8406"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lm_start = time.time()\n",
        "\n",
        "lm = LinearRegression(fit_intercept=True)\n",
        "lm.fit(X,Y)\n",
        "\n",
        "lm_end = time.time()\n",
        "\n",
        "print(lm.coef_, '\\n', lm.intercept_)\n",
        "print('SKlearn time elapsed:', lm_end - lm_start, 'seconds')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.57392068  1.35757059  0.01527565  0.        ] \n",
            " -1.8828807643601515\n",
            "SKlearn time elapsed: 0.0012409687042236328 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9QTjtT4xd41I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "SKlearn's LinearRegression() method is far quicker than previous solutions, and converges on a matching answer."
      ]
    },
    {
      "metadata": {
        "id": "7HKTeiLYd1Vk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***(d) Bonus (1 point). Write a program which computes the solution using stochastic\n",
        "gradient descent. You may use a minibatch size of 5 data points. For convergence,\n",
        "remember to decrease the learning rate over time.***"
      ]
    },
    {
      "metadata": {
        "id": "i1FngdtraoZ3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "index = T.lscalar(name='index')  # integer scalar for running through minibatch\n",
        "batch_size = 5\n",
        "\n",
        "sgd_X = theano.shared(X, name='sgd_X')\n",
        "sgd_Y = theano.shared(Y, name='sgd_Y')\n",
        "\n",
        "sgd_x = T.matrix(name='sgd_x') # feature matrix\n",
        "sgd_y = T.vector(name='sgd_y') # response vector\n",
        "sgd_w = theano.shared(np.zeros((d,1)),name='sgd_w') # model parameters\n",
        "learn_rate = theano.shared(0.7, name='learn_rate')\n",
        "\n",
        "sgd_risk = T.sum((T.dot(sgd_x,sgd_w).T - sgd_y)**2)/2/n # empirical risk\n",
        "sgd_grad_risk = T.grad(sgd_risk, wrt=sgd_w) # gradient of the risk\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dXTIzduqjdFx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1032
        },
        "outputId": "3790054d-6992-4394-fcc7-fa069db4fba1"
      },
      "cell_type": "code",
      "source": [
        "converged = False\n",
        "coeffs = np.array([0,0,0,0])\n",
        "\n",
        "train_model = theano.function(inputs=[index],\n",
        "                              outputs=sgd_risk,\n",
        "                              updates=[(sgd_w, sgd_w-learn_rate*sgd_grad_risk), \n",
        "                                       (learn_rate, learn_rate-0.05)],\n",
        "                              givens={sgd_x: sgd_X[index * batch_size: (index+1) * batch_size], \n",
        "                                      sgd_y: sgd_Y[index * batch_size: (index+1) * batch_size]})\n",
        "\n",
        "# train_model = theano.function(inputs=[],\n",
        "#                               outputs=sgd_risk,\n",
        "#                               updates=[(sgd_w, sgd_w-learn_rate*sgd_grad_risk), \n",
        "#                                        (learn_rate, learn_rate-0.02)],\n",
        "#                               givens={sgd_x:X, \n",
        "#                                       sgd_y:Y})\n",
        "sgd_start = time.time()\n",
        "index = 0\n",
        "\n",
        "while converged is False:\n",
        "  \n",
        "  print(train_model(index))\n",
        "#   print(train_model())\n",
        "  print(sgd_w.get_value())\n",
        "  \n",
        "  # Exit loop if coefficients converge to a close enough value\n",
        "  if np.allclose(coeffs, sgd_w.get_value(), rtol=1e-07, atol=1e-10):\n",
        "    sgd_end = time.time()\n",
        "    print('Result converged')\n",
        "    converged = True\n",
        "    \n",
        "  coeffs = sgd_w.get_value()\n",
        "  \n",
        "  index += 1\n",
        "  if index > 10:\n",
        "    index = 0\n",
        "  \n",
        "print('SGD elapsed time:', sgd_end - sgd_start, 'seconds')\n",
        "\n",
        "print(sgd_w.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.11992797019774265\n",
            "[[ 0.05223588]\n",
            " [ 0.00644617]\n",
            " [ 0.00348568]\n",
            " [-0.10106731]]\n",
            "0.2747017234205148\n",
            "[[ 0.07019628]\n",
            " [ 0.12947361]\n",
            " [-0.12628328]\n",
            " [-0.22009629]]\n",
            "0.3443017464721848\n",
            "[[-0.01968061]\n",
            " [ 0.24333349]\n",
            " [-0.07641392]\n",
            " [-0.33718307]]\n",
            "0.15672558694148764\n",
            "[[-0.05948728]\n",
            " [ 0.25723598]\n",
            " [-0.03317387]\n",
            " [-0.4204885 ]]\n",
            "0.1601479128034408\n",
            "[[-0.08209255]\n",
            " [ 0.32422439]\n",
            " [-0.03634549]\n",
            " [-0.4703045 ]]\n",
            "0.2715426229463849\n",
            "[[-0.22281921]\n",
            " [ 0.39518957]\n",
            " [ 0.02364032]\n",
            " [-0.54233931]]\n",
            "0.12069256599139921\n",
            "[[-0.25227445]\n",
            " [ 0.42422023]\n",
            " [-0.00411661]\n",
            " [-0.58725968]]\n",
            "0.1181507058659389\n",
            "[[-0.27509496]\n",
            " [ 0.44453467]\n",
            " [-0.01501336]\n",
            " [-0.63242975]]\n",
            "0.15739194220561442\n",
            "[[-0.29052785]\n",
            " [ 0.48052456]\n",
            " [-0.01434765]\n",
            " [-0.67591346]]\n",
            "0.019079597249791146\n",
            "[[-0.27927939]\n",
            " [ 0.4807831 ]\n",
            " [-0.01999239]\n",
            " [-0.68580205]]\n",
            "0.0\n",
            "[[-0.27927939]\n",
            " [ 0.4807831 ]\n",
            " [-0.01999239]\n",
            " [-0.68580205]]\n",
            "Result converged\n",
            "SGD elapsed time: 0.011999845504760742 seconds\n",
            "Shape.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FOicwU97d_Zv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}